---
layout: src/layouts/Default.astro
pubDate: 2023-01-01
modDate: 2023-10-04
title: Disaster Recovery
description: Guideline for configuring a DR instance of Octopus Deploy.
hideInThisSection: true
navOrder: 30
---
import OctopusInstanceMixedOSWarning from 'src/shared-content/administration/octopus-instance-mixed-os-warning.include.md';

This guide will help you setup a hot/cold disaster recovery configuration for an Octopus Deploy instance.

:::div{.hint}
This implementation guide will help setup a hot/cold disaster configuration. In our research, a multi-zonal high-availability instance will cover 90% of possible DR use cases.  A secondary, or disaster recovery instance, is meant when an entire cloud region goes offline.  If you are looking for more details on our recommendations, please refer to our white paper on [Best Practices for Self-Hosted Octopus Deploy HA/DR](https://octopus.com/whitepapers/best-practice-for-self-hosted-octopus-deploy-ha-dr).
:::

You must consider a disaster recovery solution for each of the following components of Octopus Deploy.

- **URL / load balancer** How users will access with the Octopus Deploy UI of the Disaster Recovery instance.  Will it be a unique URL for the DR instance, or will it be the same URL?  
- **Octopus Server nodes** These run the Octopus Server service. They serve user traffic and orchestrate deployments.  You will need to create or start these nodes in the secondary data center.
- **A database** Most data used by the Octopus Server nodes is stored in this database.  You'll need to have a mechanism to backup the data in the database to the secondary data center and access it once a DR event occurs.
- **Shared storage** Some larger files - like [packages](/docs/packaging-applications/package-repositories), artifacts, and deployment task logs - aren't suitable to be stored in the database, and so must be stored in a shared folder available to all nodes.  Similar to the database, you'll need a mechanism to backup the shared storage to the secondary data center and access it once a DR event occurs.

## High Availability configuration required

For a disaster recovery plan to work, you must configure your Octopus Deploy instance to support high availability.  The default installation of Octopus Deploy will configure SQL Server and the file share to run on the same virtual machine or Kubernetes cluster as the Octopus instance.  Configuring an instance for high availability will require you to:

- Move the database to a SQL Server hosted on a different server than the Octopus Deploy instance.  
- Move the files to a network file share hosted on a different server as the Octopus Deploy instance.
- Leverage a load balancer or network traffic device for user access to the UI and API.

## High Availability and Disaster Recovery

Before setting up a disaster recovery instance, we recommend following our guide for configuring [High Availability](/docs/best-practices/self-hosted-octopus/high-availability).  If you are hosting your Octopus Deploy instance in a cloud provider, you can leverage availability zones within each cloud region.  Often, managed services, such as Azure SQL or AWS RDS, provide zonal redundancy with minimal configuration.  They will automatically fail over to an availability zone if one of the zones were to go offline.

We do recommend using Octopus Deploy's high availability functionality for a hot/cold configuration between cloud regions or self-managed data centers.    

- Hot/hot configurations between cloud regions or data centers are unsupported.  
  - Octopus Deploy is sensitive to network latency, any nodes in the secondary data center will have degraded experience.  
  - Expect a nearly unusable experience on the nodes running in the secondary data center if the secondary data center requires a connection via an undersea cable (North America -> Europe, Europe -> APAC, etc.).  
  - Public cloud providers do not provide a hot/hot configuration for their managed services between their cloud regions due to latency.
- Hot/hot configurations between availability zones within a cloud region in public cloud provider are supported.  That should cover 90% of all possible disaster recovery use cases.
- Because of those factors, a hot/warm configuration will cost a lot of money per year for something that is almost never used.

## Disaster Recovery Events

A disaster recovery event is made up of two sub-events.

- Starting the Octopus Deploy instance in the secondary data center or cloud regions.
- Restarting the Octopus Deploy instance in the primary data center or cloud regions.

The challenge you'll face for either is getting data and files copied between data centers or cloud regions and keeping any data loss to a minimum.  That is because the majority of tooling and managed services must asynchronously copy data due to latency.  

### Disaster Recovery

Below are a series of steps to perform when you need to start an instance in the secondary data center or cloud region.

:::div{.hint}
**Important:** Before failing over to the secondary region or data center, consider why the outage happened. Was it a DNS configuration, and will the region return online in under an hour? Was it a weather event that caused power outages with no expected time frame for recovery? Or was it an earthquake that destroyed all the availability zones in the region? It might be best to wait until the primary region is back online.
:::

#### Database and file storage

- If using geo-replication:
  - Promote the read-only database in the secondary region to be the primary database.
  - "Fail over" or promote the read-only file storage to be the primary file storage.
- If forgoing geo-replication:
  - Create the database and file storage from the most recent backup.
- Update the connection string and file storage configuration entries to the database and file storage in the secondary region.

#### Octopus Deploy

- Create or start the Octopus nodes in the secondary region
- Enable [maintenance mode](https://octopus.com/docs/administration/managing-infrastructure/maintenance-mode)<sup>25</sup>
- Update the task cap on the nodes from 0 to your desired amount.
- Perform test deployments
- Disable maintenance mode

#### Load balancer

- Update the load balancer to point to the secondary region

### Failover to Primary

Below are a series of steps to perform once the disaster recovery event is over and you can return to the primary data center or region.

When the DR event is over, and you want to switch back to the primary region, we recommend the following steps.

- Octopus Deploy:
  - Ensure you turn off all the nodes in the primary region.
  - Turn off all the nodes in the secondary region.
- Database: 
  - If using geo-replication - follow the cloud provider's documentation to "fail over" to the primary region. Wait until the replication has finished replicating all data to the primary region.
  - If forgoing geo-replication - create a backup of the secondary region's database and restore it over the existing database in the primary region.
- File Storage:
  - If using geo-replication - follow the cloud provider's documentation to "fail over" to the primary region. Wait until the replication has finished.
  - If forgoing geo-replication - copy all the files from the secondary region to the primary region. 
- Octopus Deploy:
  - Turn on all the Octopus nodes in the primary region.
  - Enable maintenance mode.
  - Perform test deployments.
- Route traffic back to the primary region.
- After verifying the primary region is back online, destroy or turn off the Octopus nodes in the secondary region.

### Disaster recovery test recommendations

All disaster recovery plans must be periodically tested so you know they'll work when a disaster occurs.

With this recommendation, you'll likely impact users when you test the disaster recovery plan. That's because you use the managed services' "failover" functionality and route all user traffic to the secondary region. 

To test your disaster recovery plan without impacting your users, you need to create a new file system and database from backups. Create new Octopus nodes and point them to those new resources. You can use this [script from our documentation](https://oc.to/disable-all-resources-script) to disable all the targets, triggers, and anything else to prevent accidental deployment.

Whatever your disaster recovery plan, we recommend testing it to be as realistic as possible.

### Mitigating Risk

Using a public cloud provider has multiple benefits, most managed services natively support geo-redundancy, they have well documented business continuity plans, and more.  

But what is rarely discussed is what happens if all the zones in a cloud region go offline.  Everyone in that region will start executing their disaster recovery plans.  Some cloud providers, such as Azure, have a preferred secondary region via their region pairs.  That means everyone else who uses the primary region will attempt to create virtual machines and other resources in the secondary region.  

Staging the infrastructure has the cloud resources pre-configured but turned off to save costs. We recommend this if you consider Octopus Deploy a critical application that must be restored on the first day of your disaster recovery plan.

When hosting Octopus on Windows virtual machines (VMs), we recommend creating new VMs in the secondary region each time you upgrade the instance. That's preferred over long-lasting VMs. Long-lasting VMs are typically outdated, with older versions of Octopus, or haven't had the latest Windows patches.

When hosting Octopus on containers in Kubernetes, ECS, or ACS, you only need to ensure the clusters are running. Containers can be downloaded on demand. The Octopus container already has Octopus installed. 

<OctopusInstanceMixedOSWarning />

## Infrastructure

Below are our recommendations for configuring the necessary infrastructure for a disaster recovery instance.

### Database recommendations

For the SQL Server, we recommend using a managed SQL Server, such as AWS RDS, Azure SQL, or GCP Cloud SQL. Configure zonal redundancy or always-on high availability groups.

- [Azure SQL zone redundant databases](https://learn.microsoft.com/en-us/azure/azure-sql/database/high-availability-sla?view=azuresql&tabs=azure-powershell)
- [AWS SQL Server Always On availability groups](https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_SQLServerMultiAZ.html)
- [GCP Cloud SQL for SQL Server high availability](https://cloud.google.com/sql/docs/sqlserver/high-availability)

In the secondary region, create a read-only copy - or read replica - and use asynchronous geo-replication. The only time this database will get used is when all availability zones in the primary region go offline. 

- [Azure failover groups](https://learn.microsoft.com/en-us/azure/azure-sql/database/active-geo-replication-overview?view=azuresql)
- [AWS - Creating a read-only replica in a second region](https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_ReadRepl.html#USER_ReadRepl.XRgn)
- [GCP - Cross-region read replica](https://cloud.google.com/sql/docs/postgres/replication/cross-region-replicas#promote-a-replica)

If you wish to learn more about how to configure Octopus Deploy with a specific hosting option, please refer to our installation guides.

- [Self-Managed SQL Server](/docs/installation/sql-database/self-managed-sql-server)
- [AWS RDS](/docs/installation/sql-database/aws-rds)
- [Azure SQL](/docs/installation/sql-database/azure-sql)
- [GCP SQL](/docs/installation/sql-database/gcp-cloud-sql)

### File storage recommendations

We recommend using managed file storage, such as AWS FSx, Azure File Storage, or GCP Filestore. Ensure you configure the file share for at least zonal replication. 

If available, consider geo-replication for a read-only copy in the secondary cloud region. Depending on the cloud provider, you can have a read-only copy of the file storage automatically created. For example, Azure File Storage's GZRS creates 3 copies of the files in the primary region, with a fourth automatically created in the secondary region.

We've included guides for the most common file storage options we encounter.

- [Local File Storage](/docs/installation/file-storage/local-storage)
- [AWS File Storage](/docs/installation/file-storage/aws-file-storage)
- [Azure File Storage](/docs/installation/file-storage/azure-file-storage)
- [GCP File Storage](/docs/installation/file-storage/gcp-file-storage)

### Load balancer recommendations

Use a global load balancer to route Octopus Deploy http/https traffic between the primary and secondary regions. You benefit from having a single URL for users to access Octopus. In a DR event, route all traffic to the secondary regions.

Octopus Deploy only has two possible inbound connections.

1. Web UI / Web API over http/https (ports 80/443)
2. Polling Tentacles over TCP (port 10943)

#### User Interface Load Balancer

We've created guides for configuring many popular load balancers.

- Local Options
  - [Using NGINX as a reverse proxy with Octopus](/docs/installation/load-balancers/use-nginx-as-reverse-proxy)
  - [Using IIS as a reverse proxy with Octopus](/docs/installation/load-balancers/use-iis-as-reverse-proxy)
  - [Configuring Netscaler](/docs/installation/load-balancers/configuring-netscaler)
- [AWS Load Balancers](/docs/installation/load-balancers/aws-load-balancers)
- [Azure Load Balancers](/docs/installation/load-balancers/azure-load-balancers)
- [GCP Load Balancers](/docs/installation/load-balancers/gcp-load-balancers)

#### Polling Tentacles

Polling Tentacles deserve special attention due to how they work with Octopus Deploy. You must register each node that processes tasks with every Polling Tentacle.

We recommend a dedicated URL for each node in the primary region and routing all traffic through a load balancer or a traffic manager. When you have to fail over to the secondary region, update the dedicated URLs to point to a corresponding node in the secondary region.

For example, a unique address per node with the default port of `10943` would be:
  - Node1: Octo1.domain.com:10943
  - Node2: Octo2.domain.com:10943
  - Node3: Octo3.domain.com:10943

### Octopus Deploy Nodes

Generally, during a disaster recovery event, you'll need to add nodes to an existing high availability cluster.  The difference is you will be replacing all the existing nodes from the primary data center or region.

The process for that is:

1. Ensure the new host, be it Windows or Containers, can connect to the Octopus Deploy database and file storage.
2. Run a script to configure the Octopus Server node instance on a Windows machine or to start up a new container. You'll need to provide the master key and database connection information. For containers, you'll also need to provide the volume mounts.
3. Add that new node to the load balancers.
4. Update the virtual address for the polling tentacles to point to the new node.

<OctopusInstanceMixedOSWarning />

:::div{.hint}
Because all the configuration is stored in the database and blob storage, you can delete all the nodes and create new ones if you so desire.
:::

We recommend writing scripts to automate this process.  Below are some scripts to get started automating the adding of nodes to existing clusters.

- [Octopus Server on Windows](/docs/installation/automating-installation)
- [Octopus Server Linux Container](/docs/installation/octopus-server-linux-container)
- [Octopus Server in Kubernetes](/docs/installation/octopus-server-linux-container/octopus-in-kubernetes)